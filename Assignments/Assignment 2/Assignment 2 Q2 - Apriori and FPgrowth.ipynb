{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 [25 Marks]\n",
    "\n",
    "1. In this part, you are required to implement Apriori and FPgrowth algorithms on the data provided as \"data_apriori_fpgrowth/data.csv\". The dataset is of online directory of certified businesses.\n",
    "\n",
    "2. We have loaded the dataset for you.\n",
    "\n",
    "3. **You are free to use any library or implement your own algorithms**.\n",
    "\n",
    "\n",
    "**Use minimum support : 0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyfpgrowth in c:\\users\\zohair\\anaconda3\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: apyori in c:\\users\\zohair\\anaconda3\\lib\\site-packages (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyfpgrowth\n",
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import apyori\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pyfpgrowth\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['MBE', 'WBE', 'BLACK', 'Cambria Heights', '11411'])\n",
      " list(['LBE', 'Brooklyn', '11204'])\n",
      " list(['MBE', 'BLACK', 'Yorktown Heights', '10598']) ...\n",
      " list(['MBE', 'BLACK', 'Brooklyn', '11214'])\n",
      " list(['LBE', 'New York', '10016'])\n",
      " list(['MBE', 'ASIAN', 'New York', '10002'])]\n"
     ]
    }
   ],
   "source": [
    "data_rows = np.load(\"data_apriori_fpgrowth/data.npy\", allow_pickle = True)\n",
    "print(data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "1. Run Apriori Algorithm on the dataset using minimum support 0.1.\n",
    " 1. Note the run time of the algorithm to find frequent item sets.\n",
    " 1. Print all the frequent item sets found by apriori.\n",
    " 1. Print all frequent item sets of length $2$ or higher with support of $0.2$ or higher. \n",
    "1. Run FPGrowth Algorithm on the dataset using minimum support 0.1.\n",
    " 1. Note the run time of the FPGrowth algorithm to find frequent item sets.\n",
    " 1. Print all frequent item sets found by FPGrowth.\n",
    " 1. Print all frequent item sets of length $2$ or higher with support of $0.2$ or higher.\n",
    "1. Answer the following question:\n",
    " 1. Both algorithms find and return exactly the same frequent itemsets (given same parameters of support and itemset length). What difference do you note in both of the algorithms?\n",
    " 1. There were more than $1000$ transactions. Why there are too few itemsets returned by the algorithms?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time of Apriori:  0.006979942321777344\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Apriori\n",
    "start = time.time()\n",
    "ap = list(apyori.apriori(data_rows, min_support = 0.1))\n",
    "end = time.time()\n",
    "print(\"Run time of Apriori: \", end - start)\n",
    "print(len(ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN \n",
      "support: 0.20211267605633804\n",
      "\n",
      "BLACK \n",
      "support: 0.30070422535211266\n",
      "\n",
      "Brooklyn \n",
      "support: 0.15211267605633802\n",
      "\n",
      "HISPANIC \n",
      "support: 0.16408450704225352\n",
      "\n",
      "MBE \n",
      "support: 0.6711267605633803\n",
      "\n",
      "NON-MINORITY \n",
      "support: 0.3\n",
      "\n",
      "New York \n",
      "support: 0.29507042253521126\n",
      "\n",
      "WBE \n",
      "support: 0.47746478873239434\n",
      "\n",
      "ASIAN MBE \n",
      "support: 0.2\n",
      "\n",
      "MBE BLACK \n",
      "support: 0.30070422535211266\n",
      "\n",
      "Brooklyn MBE \n",
      "support: 0.11267605633802817\n",
      "\n",
      "MBE HISPANIC \n",
      "support: 0.16408450704225352\n",
      "\n",
      "MBE New York \n",
      "support: 0.1704225352112676\n",
      "\n",
      "WBE MBE \n",
      "support: 0.16901408450704225\n",
      "\n",
      "NON-MINORITY New York \n",
      "support: 0.11830985915492957\n",
      "\n",
      "WBE NON-MINORITY \n",
      "support: 0.3\n",
      "\n",
      "WBE New York \n",
      "support: 0.17535211267605633\n",
      "\n",
      "WBE NON-MINORITY New York \n",
      "support: 0.11830985915492957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All Frequent Itemsets\n",
    "for i in ap:\n",
    "    for j in i[0]:\n",
    "        print(j, end=\" \")\n",
    "    print(\"\\nsupport: \" + str(i[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN MBE \n",
      "support: 0.2\n",
      "\n",
      "MBE BLACK \n",
      "support: 0.30070422535211266\n",
      "\n",
      "WBE NON-MINORITY \n",
      "support: 0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frequent itemsets of length 2 with support of 0.2\n",
    "for i in ap:\n",
    "    if len(i[0]) == 2 and i[1] >= 0.2:\n",
    "        for j in i[0]:\n",
    "            print(j, end=\" \")\n",
    "        print(\"\\nsupport: \" + str(i[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPGrowth [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time of FPGrowth:  0.02892279624938965\n"
     ]
    }
   ],
   "source": [
    "# FPGrowth\n",
    "start = time.time()\n",
    "fp=pyfpgrowth.find_frequent_patterns(transactions=data_rows,support_threshold = (0.1 * len(data_rows)))\n",
    "end = time.time()\n",
    "print(\"Run time of FPGrowth: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brooklyn \n",
      "support: 0.15211267605633802\n",
      "\n",
      "Brooklyn MBE \n",
      "support: 0.11267605633802817\n",
      "\n",
      "HISPANIC \n",
      "support: 0.16408450704225352\n",
      "\n",
      "HISPANIC MBE \n",
      "support: 0.16408450704225352\n",
      "\n",
      "ASIAN \n",
      "support: 0.20211267605633804\n",
      "\n",
      "ASIAN MBE \n",
      "support: 0.2\n",
      "\n",
      "NON-MINORITY New York \n",
      "support: 0.11830985915492957\n",
      "\n",
      "NON-MINORITY New York WBE \n",
      "support: 0.11830985915492957\n",
      "\n",
      "MBE New York \n",
      "support: 0.1704225352112676\n",
      "\n",
      "New York WBE \n",
      "support: 0.17535211267605633\n",
      "\n",
      "NON-MINORITY \n",
      "support: 0.3\n",
      "\n",
      "NON-MINORITY WBE \n",
      "support: 0.3\n",
      "\n",
      "BLACK \n",
      "support: 0.30070422535211266\n",
      "\n",
      "BLACK MBE \n",
      "support: 0.30070422535211266\n",
      "\n",
      "WBE \n",
      "support: 0.47746478873239434\n",
      "\n",
      "MBE WBE \n",
      "support: 0.16901408450704225\n",
      "\n",
      "MBE \n",
      "support: 0.6711267605633803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All Frequent Itemsets\n",
    "for i in fp:\n",
    "    for j in i:\n",
    "        print(j, end=\" \")\n",
    "    print(\"\\nsupport: \" + str(fp[i]/len(data_rows))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN MBE \n",
      "support: 0.2\n",
      "\n",
      "NON-MINORITY WBE \n",
      "support: 0.3\n",
      "\n",
      "BLACK MBE \n",
      "support: 0.30070422535211266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frequent itemsets of length 2 with support of 0.2\n",
    "for i in fp:\n",
    "    if len(i) == 2 and fp[i] >= (0.2*len(data_rows)):\n",
    "        for j in i:\n",
    "            print(j, end=\" \")\n",
    "        print(\"\\nsupport: \" + str(fp[i]/len(data_rows))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer to the Questions [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both algorithms find and return exactly the same frequent itemsets (given same parameters of support and itemset length). What difference do you note in both of the algorithms?\n",
    "\n",
    "##### Answer:\n",
    "Although the results are same, FPGrowth is known to surpass Apriori in terms of performance at scale. However, this is not the case above since FPGrowth has a higher run time for this data set. The only viable reason for this is that since FPGrowth involves recursion, it takes more time when the data set is not large like ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There were more than  1000  transactions. Why there are too few itemsets returned by the algorithms?\n",
    "##### Answer:\n",
    "This is because the item sets were pruned on minimum support. Since only three itemsets show up for a minimum support of 0.2, this shows that there are not a lot of frequent patterns in the data set despite its size so we can think of it as somewhat sparse. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
